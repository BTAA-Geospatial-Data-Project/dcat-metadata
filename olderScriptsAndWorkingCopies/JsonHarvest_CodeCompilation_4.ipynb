{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules necessary for geospatial resource harvest and analysis.\n",
    "# JSON & URL modules for methods of scraping harvest data from internet.\n",
    "# CSV module needed for dataset export once iterated through.\n",
    "# Other modules for clean-up and conversion of data fields & attributes.\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import datetime\n",
    "import decimal\n",
    "import json\n",
    "import operator\n",
    "import regex\n",
    "import codecs\n",
    "import progressbar as pb\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schemaAllFields():\n",
    "    # Function to define and name metadata standard\n",
    "    ## Project Open Data Schema v1.1 ALL metadata fields.\n",
    "    # Template found at https://project-open-data.cio.gov/v1.1/schema/\n",
    "    \n",
    "    ## root == Root JSON Dict, dat == dataset Dict, pub == publisher Dict,\n",
    "    ##  con == contactPoint Dict, dis == distribution Dict\n",
    "    \n",
    "    allRootList = [\"@context\", \"@id\", \"@type\",\n",
    "                   \"conformsTo\", \"describedBy\", \"dataset\"]\n",
    "    allDatList = [\"@type\", \"identifier\", \"title\", \"description\", \"keyword\",\n",
    "                  \"issued\", \"modified\", \"publisher\", \"contactPoint\",\n",
    "                  \"accessLevel\", \"distribution\", \"landingPage\", \"webService\",\n",
    "                  \"license\", \"spatial\", \"theme\", \"temporal\", \"describedBy\",\n",
    "                  \"isPartOf\", \"references\", \"rights\", \"accrualPeriodicity\",\n",
    "                  \"conformsTo\", \"describedByType\", \"language\", \"bureauCode\",\n",
    "                  \"programCode\", \"dataQuality\", \"primaryITInvestmentUII\",\n",
    "                  \"systemOfRecords\"]\n",
    "    allConList = [\"@type\", \"fn\", \"hasEmail\"]\n",
    "    allPubList = [\"@type\", \"name\", \"subOrganizationOf\"]\n",
    "    allDisList = [\"@type\", \"title\", \"format\", \"mediaType\", \n",
    "                  \"accessURL\", \"downloadURL\", \"description\", \n",
    "                  \"conformsTo\", \"describedBy\", \"describedByType\"]\n",
    "\n",
    "# Dictionary variable defined for key-value matching.\n",
    "    schemaDict = {\"root\": allRoot, \"dat\": allDat, \n",
    "                  \"con\": allCon, \"pub\": allPub, \"dis\": allDis}\n",
    "    \n",
    "    return schemaDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion of resultant dictionary to list if better for user script editing.\n",
    "def getSchema():\n",
    "    schemaDict = schemaAllFields()\n",
    "    schemaKeys = schemaDict.keys()\n",
    "    schemaList = []\n",
    "    for key in schemaKeys:\n",
    "        vals = schemaDict[key]\n",
    "        pairing = [key, vals]\n",
    "        schemaList.append(pairing)\n",
    "        \n",
    "    return [schemaDict, schemaList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathDefs(portalCsvPath, portalCsvFile, workingDir):\n",
    "    # Function to generate/establish working output file directory.\n",
    "    \n",
    "    cPath = os.path.normpath(portalCsvPath)\n",
    "    cFile = os.path.join(cPath, portalCsvFile + \".csv\")\n",
    "    wDir = os.path.normpath(workingDir)\n",
    "    jPath = os.path.join(wDir, \"jsons\")\n",
    "    rPath = os.path.join(wDir, \"reports\")    \n",
    "    if not os.path.exists(jPath):\n",
    "        os.mkdir(jPath)\n",
    "    if not os.path.exists(rPath):\n",
    "        os.mkdir(rPath)    \n",
    "    print(\"Working data & directory structure defined.\\n\")\n",
    "    return [cFile, wDir, jPath, rPath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harvestJsons():    \n",
    "    with open(cFile) as c:\n",
    "        reader = csv.DictReader(c)\n",
    "        for row in reader:\n",
    "            pName = row[\"portalName\"]\n",
    "            url = row[\"URL\"]\n",
    "            nJson = \"%s_%s_Harvest.json\" % (pName, today)\n",
    "            harvestJson = os.path.join(jPath, nJson)\n",
    "            response = urlopen(url)\n",
    "            reader = codecs.getreader(\"utf-8\")\n",
    "            pScrape = json.load(reader(response))\n",
    "            widgets = [pb.Percentage(), pb.Bar()]\n",
    "            bar = pb.ProgressBar(widgets=widgets, max_value=1000).start()\n",
    "            for i in range(100):\n",
    "                with open(harvestJson, \"w\") as outJson:\n",
    "                    json.dump(pScrape, outJson)\n",
    "                bar.update(10 * i + 1)\n",
    "            bar.finish()\n",
    "            print(\"    *\", nJson)\n",
    "        print(\"\\n\", \"-\" * 80, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idSlice(identifierURL):\n",
    "    identifier = []\n",
    "    u = identifierURL\n",
    "    arc = u.find(\"/datasets/\")\n",
    "    soc = u.find(\"/d/\")\n",
    "    i = arc + 10\n",
    "    i2 = soc\n",
    "    if i > 0:\n",
    "        identifier.append(u[i:])\n",
    "    elif i2 > 0:\n",
    "        identifier.append(u[-9:])\n",
    "    else:\n",
    "        identifier.append(\"check identifier URL\")\n",
    "    uuid = str(identifier[0])\n",
    "    return uuid\n",
    "\n",
    "def issuedSlice(issuedDate):\n",
    "    isoIssued = []\n",
    "    inStr = issuedDate    \n",
    "    yr, mo, dy = int(inStr[:4]), int(inStr[5:7]), int(inStr[8:10])\n",
    "    dateFormat = datetime.date(yr, mo, dy).isoformat()\n",
    "    isoIssued.append(dateFormat)\n",
    "    issued = str(isoIssued[0])\n",
    "    return issued\n",
    "\n",
    "def boundingBox(spatialString):\n",
    "    bbox = []\n",
    "    formatBbox = []\n",
    "    inStr = spatialString\n",
    "    typeDmal = decimal.Decimal\n",
    "    fix4 = typeDmal(\"0.0001\")    \n",
    "    for coord in inStr.split(\",\"):\n",
    "        coordFix = typeDmal(coord).quantize(fix4)\n",
    "        bbox.append(str(coordFix))            \n",
    "    return bbox\n",
    "\n",
    "def getData(inJson):\n",
    "    hasVals = []\n",
    "    for key in inJson[\"dataset\"]:\n",
    "        identifier = key[\"identifier\"]\n",
    "        ident = [\"identifier\", identifier]\n",
    "        hasVals.append(idSlice(ident[1]))\n",
    "        \n",
    "        dsetTitle = key[\"title\"]\n",
    "        listTitle = [\"title\", dsetTitle]\n",
    "        hasVals.append(listTitle[1])\n",
    "        \n",
    "        dsetDescript = key[\"description\"]\n",
    "        listDescript = [\"description\", dsetDescript]\n",
    "        hasVals.append(listDescript[1])\n",
    "        \n",
    "        dsetKeywords = key[\"keyword\"]\n",
    "        listKeywords = [\"keyword\", dsetKeywords]\n",
    "        hasVals.append(listKeywords[1])\n",
    "        \n",
    "        dsetIssued = key[\"issued\"]\n",
    "        listIssued = [\"issued\", dsetIssued]\n",
    "        hasVals.append(issuedSlice(listIssued[1]))\n",
    "        \n",
    "        dsetSpatial = key[\"spatial\"]\n",
    "        listSpatial = [\"spatial\", dsetSpatial]        \n",
    "        hasVals.append(\",\".join(boundingBox(listSpatial[1])))\n",
    "        \n",
    "        dsetPublisher = key[\"publisher\"][\"name\"]\n",
    "        listPublisher = [\"name\", dsetPublisher]\n",
    "        hasVals.append(listPublisher[1])\n",
    "        \n",
    "        dsetLandingPage = key[\"landingPage\"]\n",
    "        listLandingPage = [\"landingPage\", dsetLandingPage]\n",
    "        hasVals.append(listLandingPage[1])\n",
    "        \n",
    "        dsetWebService = key[\"webService\"]\n",
    "        listWebService = [\"webService\", dsetWebService]\n",
    "        hasVals.append(listWebService[1])\n",
    "        \n",
    "        dsetDistrib = key[\"distribution\"]        \n",
    "        distribValList = [\"Shapefile\", \"GeoJSON\", \"OGC WFS\", \"OGC WMS\"]\n",
    "        for z in range(len(dsetDistrib)):           \n",
    "            for index, (keys, values) in enumerate(dsetDistrib[z].items()):\n",
    "                if keys == \"title\":\n",
    "                    if values in distribValList:                    \n",
    "                        hasVals.append(values)\n",
    "                listVals = [values]\n",
    "                for val in listVals:\n",
    "                    if \".geojson\" in val:\n",
    "                        hasVals.append(val)\n",
    "                    elif \".zip\" in val:\n",
    "                        hasVals.append(val)\n",
    "                    elif \"=WFS\" in val:\n",
    "                        hasVals.append(val)\n",
    "                    elif \"=WMS\" in val:\n",
    "                        hasVals.append(val)\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "    return hasVals\n",
    "\n",
    "def harvestReports():\n",
    "    with open(cFile) as c:\n",
    "        reader = csv.DictReader(c)\n",
    "        for row in reader:\n",
    "            pName = row[\"portalName\"]\n",
    "            nReport = \"%s_%s_HarvestReport.csv\" % (pName, today)\n",
    "            harvestReport = os.path.join(rPath, nReport)\n",
    "            with open(csvOut, \"w\") as f:\n",
    "                writer = csv.writer(f, dialect=\"unix\")    \n",
    "                for row in rows:\n",
    "                    writer.writerow(row)\n",
    "    \n",
    "#             with open(harvestReport, 'w') as outfile:\n",
    "#                 csvout = csv.writer(outfile)\n",
    "#                 for row in harvestList:\n",
    "#                     csvout.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User input, Function Call Cell 1\n",
    "\n",
    "## ISO format current date\n",
    "today = datetime.date.today().isoformat().replace(\"-\",\"\")\n",
    "\n",
    "# User input data elements to provide parameters for geoportal harvest.\n",
    "userIn1 = input(\"*Enter path of folder containing formatted geoportal harvest CSV \\n(C:folderPath, Windows or UNIX-style):\\n\")\n",
    "print(\"\")\n",
    "userIn2 = input(\"*Enter name of formatted geoportal harvest CSV \\n(C:formattedFile, No extension on filename):\\n\")\n",
    "print(\"\")\n",
    "userIn3 = input(\"*Enter path of data output folder \\n(C:folderPath, Windows or UNIX-style):\\n\")\n",
    "print(\"\\n\", \"-\" * 80, \"\\n\")\n",
    "\n",
    "# Input/output file names & paths\n",
    "pathLookup = pathDefs(userIn1, userIn2, userIn3)\n",
    "cFile = pathLookup[0]\n",
    "wDir = pathLookup[1]\n",
    "jPath = pathLookup[2]\n",
    "rPath = pathLookup[3]\n",
    "\n",
    "print(\"Input CSV file, formatted geoportal harvest list:\\n   \", cFile)\n",
    "print(\"Script output file directory:\\n   \", wDir)\n",
    "print(\"Output folder, geoportal response JSONs:\\n   \", jPath)\n",
    "print(\"Output folder, JSON to CSV conversion Reports:\\n   \", rPath)\n",
    "print(\"\\n\", \"-\" * 80, \"\\n\")\n",
    "print(\"Saving JSONs:\\n   \")\n",
    "\n",
    "# Run portal harvest script\n",
    "harvestJsons()\n",
    "\n",
    "# responseJsons = harvestJsons()\n",
    "jList = []\n",
    "for newJson in os.listdir(jPath):\n",
    "    jList.append(newJson)\n",
    "\n",
    "# INSERT JSONCOMPARISON SCRIPT HERE\n",
    "\n",
    "# datAll = lScrape[0][\"dataset\"]\n",
    "# testFile = os.path.join(jPath, \"04c-02_20181205_Harvest.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatialList = []\n",
    "\n",
    "# Iterate through JSONs\n",
    "for j in jList:\n",
    "    j = harvestJson\n",
    "    with open(harvestJson, \"r\") as targetJson:\n",
    "        readJson = json.load(targetJson)\n",
    "\n",
    "# Run JSON dataset key/value capture iteration.\n",
    "getData(readJson)\n",
    "\n",
    "### ZIP UP result lists for CSV outfile prep.\n",
    "# rows = zip(idList, tiList, descList, kewList, issList, spList, pubList, \n",
    "#            infoList, servList, licList, thmList)\n",
    "\n",
    "# csvOut = r\"C:\\Users\\Andy\\Desktop\\Work\\Development\\Script\\A_proj_Json2Csv\\Testing\\TestCSVs\\testing.csv\"\n",
    "# csvDistOut = r\"C:\\Users\\Andy\\Desktop\\Work\\Development\\Script\\A_proj_Json2Csv\\Testing\\TestCSVs\\testingDist.csv\"\n",
    "\n",
    "# with open(csvOut, \"w\") as f:\n",
    "#     writer = csv.writer(f, dialect=\"unix\")    \n",
    "#     for row in rows:\n",
    "#         writer.writerow(row)\n",
    "\n",
    "# def harvestReports():\n",
    "#     with open(cFile) as c:\n",
    "#         reader = csv.DictReader(c)\n",
    "#         for row in reader:\n",
    "#             pName = row[\"portalName\"]\n",
    "#             nReport = \"%s_%s_HarvestReport.csv\" % (pName, today)\n",
    "#             harvestReport = os.path.join(rPath, nReport)\n",
    "#             with open(harvestReport, 'w') as outfile:\n",
    "#                 csvout = csv.writer(outfile)\n",
    "#                 for row in harvestList:\n",
    "#                     csvout.writerow(row)\n",
    "\n",
    "# def csvOutfile(csvFile, dirPath):\n",
    "#     # Function to generate a CSV output file of harvest results.\n",
    "    \n",
    "#     inCsv = csvFile\n",
    "#     path = dirPath\n",
    "#     # sys.stdout.encoding='utf-8'\n",
    "#     with open(inCsv) as f:\n",
    "#         reader = csv.DictReader(f)\n",
    "#         for row in reader:\n",
    "#             portalName = row[\"portalName\"]\n",
    "#     report2 = (in2 + r'\\reports\\%s_%s_HarvestReport.csv') % (portalName, today)\n",
    "#     with open(report2, 'w', encoding='cp1252', errors='replace') as outfile:\n",
    "#         csvout = csv.writer(outfile)\n",
    "#         for row in harvestList:\n",
    "#             csvout.writerow(row)\n",
    "#     print(today, \"Report for\", portalName, \"complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fieldDict = schemaAllFields()\n",
    "# fieldKeys = fieldDict.keys()\n",
    "# datFieldList = fieldDict.get('dat')\n",
    "# newDict = {}\n",
    "# c = 0\n",
    "# for d in datFieldList:\n",
    "#     newDict[d] = c\n",
    "#     c += 1\n",
    "# dSetDict_keys = set(dSet.keys())\n",
    "# newDict_keys = set(newDict.keys())\n",
    "# shared_keys = set(newDict.keys()) & set(dSet.keys())\n",
    "\n",
    "# with open(testFile, \"r\") as read_file:\n",
    "#     readJson = json.load(read_file)\n",
    "#     rootKeys = readJson.keys()\n",
    "#     dSet = readJson[\"dataset\"][0]\n",
    "#     dSetList = list(dSet.keys())\n",
    "\n",
    "# def ordered_set(in_list):\n",
    "#     out_list = []\n",
    "#     added = set()\n",
    "#     for val in in_list:\n",
    "#         if not val in added:\n",
    "#             out_list.append(val)\n",
    "#             added.add(val)\n",
    "#     return out_list\n",
    "\n",
    "# fieldList = []\n",
    "# rKeys = rFieldDict.keys()\n",
    "# for key in rKeys:   \n",
    "#     vals = rFieldDict[key]\n",
    "#     for v in vals:\n",
    "#         fieldList.append(v)\n",
    "\n",
    "# def parseJsons():\n",
    "#     for open(os.list)\n",
    "#     for open(newJson in os.listdir(jPath, \"r\")) as inJson:\n",
    "#         readJson = json.load(inJson)\n",
    "#         root = readJson[0]\n",
    "#         dSet = root[\"dataset\"]\n",
    "#         resourceCount = len(dSet)        \n",
    "#     allKeysList = []\n",
    "#     allValsList = []    \n",
    "#     allKeys = allFieldsDict.keys()\n",
    "#     for aKey in allKeys:\n",
    "#         allKeysList.append(aKey)\n",
    "#         allVals = allFieldsDict[aKey]\n",
    "#         for aVal in allVals:\n",
    "#             allValsList.append(aVal)\n",
    "\n",
    "# def schemaParse():\n",
    "#     # Assemble schema field names in preferred spreadsheet order.\n",
    "    \n",
    "#     allFieldsDict = schemaAllFields()\n",
    "#     allKeysList = []\n",
    "#     allValsList = []\n",
    "    \n",
    "#     allKeys = allFieldsDict.keys()\n",
    "#     for aKey in allKeys:\n",
    "#         allKeysList.append(aKey)\n",
    "#         allVals = allFieldsDict[aKey]\n",
    "#         for aVal in allVals:\n",
    "#             allValsList.append(aVal)\n",
    "            \n",
    "#     return allKeysList, allValsList\n",
    "\n",
    "# def dictOrg(dictionary):\n",
    "#     dictTuple = []\n",
    "#     d = dictionary\n",
    "#     for index, (key, value) in enumerate(d.items()):\n",
    "#         dTuple = (index, key, value)\n",
    "#         dictTuple.append(dTuple)        \n",
    "#     return dictTuple\n",
    "\n",
    "# a = (1,2,3)\n",
    "# (one,two,three) = a\n",
    "# print(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
